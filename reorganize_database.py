#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Script pour r√©organiser la base de donn√©es SQLite :
1. Renommer la table scraper_pdfdocument en scraper_wordsdocument
2. Supprimer tous les enregistrements li√©s aux fichiers .pdf
3. Ajouter les fichiers .docx des r√©pertoires sp√©cifi√©s
"""

import os
import sys
import sqlite3
import logging
from datetime import datetime
from pathlib import Path

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def get_db_connection():
    """Obtenir une connexion √† la base de donn√©es SQLite"""
    db_path = 'db.sqlite3'
    if not os.path.exists(db_path):
        logger.error(f"Base de donn√©es non trouv√©e : {db_path}")
        return None
    return sqlite3.connect(db_path)

def rename_table(conn):
    """√âtape 1 : Renommer la table scraper_pdfdocument en scraper_wordsdocument"""
    try:
        cursor = conn.cursor()
        
        # V√©rifier si la table scraper_pdfdocument existe
        cursor.execute("""
            SELECT name FROM sqlite_master 
            WHERE type='table' AND name='scraper_pdfdocument'
        """)
        
        if cursor.fetchone():
            # V√©rifier si scraper_wordsdocument existe d√©j√†
            cursor.execute("""
                SELECT name FROM sqlite_master 
                WHERE type='table' AND name='scraper_wordsdocument'
            """)
            
            if cursor.fetchone():
                logger.info("La table scraper_wordsdocument existe d√©j√†, suppression...")
                cursor.execute("DROP TABLE scraper_wordsdocument")
            
            # Renommer la table
            cursor.execute("ALTER TABLE scraper_pdfdocument RENAME TO scraper_wordsdocument")
            logger.info("‚úÖ Table renomm√©e : scraper_pdfdocument ‚Üí scraper_wordsdocument")
        else:
            logger.warning("Table scraper_pdfdocument non trouv√©e")
        
        conn.commit()
        return True
        
    except Exception as e:
        logger.error(f"Erreur lors du renommage de la table : {e}")
        return False

def clean_pdf_records(conn):
    """√âtape 2 : Supprimer tous les enregistrements li√©s aux fichiers .pdf"""
    try:
        cursor = conn.cursor()
        
        # Compter les enregistrements PDF avant suppression
        cursor.execute("""
            SELECT COUNT(*) FROM scraper_wordsdocument 
            WHERE filename LIKE '%.pdf' OR filename LIKE '%.pdf.%'
        """)
        pdf_count = cursor.fetchone()[0]
        
        if pdf_count > 0:
            # Supprimer les enregistrements PDF
            cursor.execute("""
                DELETE FROM scraper_wordsdocument 
                WHERE filename LIKE '%.pdf' OR filename LIKE '%.pdf.%'
            """)
            logger.info(f"‚úÖ {pdf_count} enregistrements PDF supprim√©s")
        else:
            logger.info("Aucun enregistrement PDF trouv√©")
        
        conn.commit()
        return True
        
    except Exception as e:
        logger.error(f"Erreur lors de la suppression des enregistrements PDF : {e}")
        return False

def get_file_size(file_path):
    """Obtenir la taille d'un fichier"""
    try:
        return os.path.getsize(file_path)
    except:
        return 0

def add_docx_files(conn):
    """√âtape 3 : Ajouter les fichiers .docx des r√©pertoires sp√©cifi√©s"""
    directories = [
        r'C:\Users\anouar\Downloads\Scraping-web-sites-auto-naviguation\Scraping-web-sites-auto-naviguation-master\finances.gov.ma\words_downloads',
        r'C:\Users\anouar\Downloads\Scraping-web-sites-auto-naviguation\Scraping-web-sites-auto-naviguation-master\cese.ma\pdf_downloads',
        r'C:\Users\anouar\Downloads\Scraping-web-sites-auto-naviguation\Scraping-web-sites-auto-naviguation-master\agriculture.gov.ma\words_downloads',
        r'C:\Users\anouar\Downloads\Scraping-web-sites-auto-naviguation\Scraping-web-sites-auto-naviguation-master\oecd.org\words_downloads',
        r'C:\Users\anouar\Downloads\Scraping-web-sites-auto-naviguation\Scraping-web-sites-auto-naviguation-master\bkam.ma\bkam.ma\pdf_downloads\Communiques\words_downloads',
        r'C:\Users\anouar\Downloads\Scraping-web-sites-auto-naviguation\Scraping-web-sites-auto-naviguation-master\bkam.ma\bkam.ma\pdf_downloads\Discours\words_downloads'
    ]
    
    try:
        cursor = conn.cursor()
        
        # Obtenir la liste des fichiers d√©j√† pr√©sents
        cursor.execute("SELECT filename FROM scraper_wordsdocument")
        existing_files = {row[0] for row in cursor.fetchall()}
        
        added_count = 0
        skipped_count = 0
        
        for directory in directories:
            if not os.path.exists(directory):
                logger.warning(f"R√©pertoire non trouv√© : {directory}")
                continue
            
            logger.info(f"Scan du r√©pertoire : {directory}")
            
            # Chercher tous les fichiers .docx
            for root, dirs, files in os.walk(directory):
                for file in files:
                    if file.lower().endswith('.docx'):
                        full_path = os.path.join(root, file)
                        
                        # V√©rifier si le fichier existe d√©j√†
                        if file in existing_files:
                            logger.debug(f"Fichier d√©j√† pr√©sent : {file}")
                            skipped_count += 1
                            continue
                        
                        # Obtenir les m√©tadonn√©es du fichier
                        file_size = get_file_size(full_path)
                        source_dir = os.path.basename(os.path.dirname(directory))
                        
                        # Ins√©rer le nouveau fichier
                        cursor.execute("""
                            INSERT INTO scraper_wordsdocument (
                                filename, file_path, file_size, source_directory,
                                is_processed, extraction_success, analysis_success,
                                content, content_length, language, theme, confidence,
                                summary, error_message, is_retained, page_count,
                                created_at, updated_at
                            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """, (
                            file,
                            full_path,
                            file_size,
                            source_dir,
                            False,  # is_processed
                            False,  # extraction_success
                            False,  # analysis_success
                            "",     # content
                            0,      # content_length
                            None,   # language
                            None,   # theme
                            "Moyen", # confidence
                            "",     # summary
                            None,   # error_message
                            True,   # is_retained
                            0,      # page_count
                            datetime.now().isoformat(),  # created_at
                            datetime.now().isoformat()   # updated_at
                        ))
                        
                        added_count += 1
                        existing_files.add(file)  # Ajouter √† la liste pour √©viter les doublons
                        logger.info(f"‚úÖ Ajout√© : {file}")
        
        conn.commit()
        logger.info(f"\n=== R√âSUM√â AJOUT FICHIERS ===")
        logger.info(f"Fichiers ajout√©s : {added_count}")
        logger.info(f"Fichiers ignor√©s (doublons) : {skipped_count}")
        
        return True
        
    except Exception as e:
        logger.error(f"Erreur lors de l'ajout des fichiers .docx : {e}")
        return False

def get_table_stats(conn):
    """Obtenir les statistiques de la table"""
    try:
        cursor = conn.cursor()
        
        # Compter le total
        cursor.execute("SELECT COUNT(*) FROM scraper_wordsdocument")
        total = cursor.fetchone()[0]
        
        # Compter par extension
        cursor.execute("""
            SELECT 
                CASE 
                    WHEN filename LIKE '%.docx' THEN 'DOCX'
                    WHEN filename LIKE '%.pdf' THEN 'PDF'
                    ELSE 'AUTRE'
                END as type,
                COUNT(*) as count
            FROM scraper_wordsdocument 
            GROUP BY type
        """)
        
        stats = cursor.fetchall()
        
        logger.info(f"\n=== STATISTIQUES FINALES ===")
        logger.info(f"Total d'enregistrements : {total}")
        for stat_type, count in stats:
            logger.info(f"{stat_type} : {count}")
        
    except Exception as e:
        logger.error(f"Erreur lors de l'obtention des statistiques : {e}")

def main():
    """Fonction principale"""
    logger.info("üöÄ D√©but de la r√©organisation de la base de donn√©es")
    
    # Connexion √† la base de donn√©es
    conn = get_db_connection()
    if not conn:
        return
    
    try:
        # √âtape 1 : Renommer la table
        logger.info("\nüß© √âTAPE 1 : Renommage de la table")
        if not rename_table(conn):
            logger.error("√âchec du renommage de la table")
            return
        
        # √âtape 2 : Nettoyer les donn√©es PDF
        logger.info("\nüßπ √âTAPE 2 : Nettoyage des donn√©es PDF")
        if not clean_pdf_records(conn):
            logger.error("√âchec du nettoyage des donn√©es PDF")
            return
        
        # √âtape 3 : Ajouter les fichiers .docx
        logger.info("\nüì• √âTAPE 3 : Ajout des fichiers .docx")
        if not add_docx_files(conn):
            logger.error("√âchec de l'ajout des fichiers .docx")
            return
        
        # Statistiques finales
        get_table_stats(conn)
        
        logger.info("\n‚úÖ R√©organisation termin√©e avec succ√®s !")
        
    finally:
        conn.close()

if __name__ == '__main__':
    main()