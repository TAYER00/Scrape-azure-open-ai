#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
D√©monstration de la gestion automatique des sites web et relations

Ce script montre comment utiliser les fonctionnalit√©s de gestion des sites web
et des relations website_id dans la base de donn√©es SQLite.

Auteur: Assistant IA
Date: 2025-07-25
"""

import sqlite3
import logging
from datetime import datetime

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def demo_website_extraction():
    """D√©montre l'extraction de noms de sites √† partir de chemins de fichiers"""
    logger.info("=== D√âMONSTRATION: Extraction de noms de sites ===")
    
    # Import de la fonction depuis reorganize_database
    from reorganize_database import extract_site_name_from_path
    
    # Exemples de chemins de fichiers
    test_paths = [
        r"agriculture.gov.ma\pdf_downloads\document1.pdf",
        r"bkam.ma\bkam.ma\pdf_downloads\Communiques\pdf_scraper\rapport.pdf",
        r"cese.ma\pdf_downloads\avis.pdf",
        r"finances.gov.ma\pdf_downloads\budget.pdf",
        r"oecd.org\pdf_downloads\study.pdf",
        r"unknown_site\documents\file.pdf"  # Cas d'erreur
    ]
    
    for path in test_paths:
        site_name = extract_site_name_from_path(path)
        status = "‚úÖ" if site_name else "‚ùå"
        logger.info(f"{status} {path[:50]}... ‚Üí {site_name or 'Non d√©tect√©'}")

def demo_database_queries():
    """D√©montre des requ√™tes utiles sur la base de donn√©es"""
    logger.info("\n=== D√âMONSTRATION: Requ√™tes de base de donn√©es ===")
    
    conn = sqlite3.connect('db.sqlite3')
    cursor = conn.cursor()
    
    try:
        # 1. Requ√™te: PDFs par site avec comptage
        logger.info("\nüìä Requ√™te 1: Nombre de PDFs par site")
        cursor.execute("""
            SELECT w.name, COUNT(p.id) as count, w.url
            FROM scraper_website w
            LEFT JOIN scraper_scrapedpdf p ON w.id = p.website_id
            GROUP BY w.id, w.name, w.url
            ORDER BY count DESC
        """)
        
        for site_name, count, url in cursor.fetchall():
            logger.info(f"  {site_name}: {count} PDFs ({url})")
        
        # 2. Requ√™te: PDFs r√©cents par site
        logger.info("\nüìÖ Requ√™te 2: PDFs les plus r√©cents par site")
        cursor.execute("""
            SELECT w.name, p.title, p.downloaded_at
            FROM scraper_scrapedpdf p
            JOIN scraper_website w ON p.website_id = w.id
            ORDER BY p.downloaded_at DESC
            LIMIT 10
        """)
        
        for site_name, title, downloaded_at in cursor.fetchall():
            logger.info(f"  {site_name}: {title[:40]}... ({downloaded_at[:19]})")
        
        # 3. Requ√™te: Recherche de PDFs par mot-cl√©
        logger.info("\nüîç Requ√™te 3: Recherche par mot-cl√© 'Dahir'")
        cursor.execute("""
            SELECT w.name, p.title
            FROM scraper_scrapedpdf p
            JOIN scraper_website w ON p.website_id = w.id
            WHERE p.title LIKE '%Dahir%'
            LIMIT 5
        """)
        
        for site_name, title in cursor.fetchall():
            logger.info(f"  {site_name}: {title}")
        
        # 4. Requ√™te: Statistiques globales
        logger.info("\nüìà Requ√™te 4: Statistiques globales")
        cursor.execute("SELECT COUNT(*) FROM scraper_website")
        website_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM scraper_scrapedpdf")
        pdf_count = cursor.fetchone()[0]
        
        cursor.execute("""
            SELECT COUNT(*) FROM scraper_scrapedpdf 
            WHERE website_id IS NOT NULL
        """)
        linked_count = cursor.fetchone()[0]
        
        logger.info(f"  Sites web: {website_count}")
        logger.info(f"  PDFs total: {pdf_count}")
        logger.info(f"  PDFs li√©s: {linked_count}")
        logger.info(f"  Taux de liaison: {(linked_count/pdf_count*100):.1f}%")
        
    except Exception as e:
        logger.error(f"Erreur lors des requ√™tes: {e}")
    finally:
        conn.close()

def demo_manual_site_creation():
    """D√©montre la cr√©ation manuelle d'un nouveau site web"""
    logger.info("\n=== D√âMONSTRATION: Cr√©ation manuelle d'un site ===")
    
    conn = sqlite3.connect('db.sqlite3')
    cursor = conn.cursor()
    
    try:
        # V√©rifier si le site existe d√©j√†
        test_site = "example.gov.ma"
        cursor.execute("SELECT id FROM scraper_website WHERE name = ?", (test_site,))
        
        if cursor.fetchone():
            logger.info(f"‚ÑπÔ∏è Le site {test_site} existe d√©j√†")
        else:
            # Cr√©er le nouveau site
            cursor.execute("""
                INSERT INTO scraper_website (name, url, created_at)
                VALUES (?, ?, ?)
            """, (
                test_site,
                f"https://www.{test_site}",
                datetime.now().isoformat()
            ))
            
            conn.commit()
            logger.info(f"‚úÖ Site {test_site} cr√©√© avec succ√®s")
            
            # R√©cup√©rer l'ID du nouveau site
            cursor.execute("SELECT id FROM scraper_website WHERE name = ?", (test_site,))
            new_id = cursor.fetchone()[0]
            logger.info(f"   ID assign√©: {new_id}")
            
    except Exception as e:
        logger.error(f"Erreur lors de la cr√©ation: {e}")
    finally:
        conn.close()

def demo_usage_examples():
    """Affiche des exemples d'utilisation des scripts"""
    logger.info("\n=== EXEMPLES D'UTILISATION ===")
    
    examples = [
        {
            "title": "1. Remplir la base avec gestion automatique des sites",
            "command": "python reorganize_database.py",
            "description": "Cr√©e automatiquement les sites web et ajoute les PDFs avec relations"
        },
        {
            "title": "2. G√©rer uniquement les sites web et relations",
            "command": "python manage_websites.py",
            "description": "Cr√©e les sites web et met √† jour les relations existantes"
        },
        {
            "title": "3. V√©rifier l'√©tat des relations",
            "command": "python verify_website_relations.py",
            "description": "Affiche des statistiques et v√©rifie l'int√©grit√© des donn√©es"
        },
        {
            "title": "4. D√©monstration compl√®te",
            "command": "python demo_website_management.py",
            "description": "Ex√©cute cette d√©monstration avec exemples et tests"
        }
    ]
    
    for example in examples:
        logger.info(f"\n{example['title']}:")
        logger.info(f"  Commande: {example['command']}")
        logger.info(f"  Description: {example['description']}")

def main():
    """Fonction principale de d√©monstration"""
    logger.info("üöÄ D√âMONSTRATION: Gestion automatique des sites web")
    logger.info("=" * 60)
    
    try:
        # 1. D√©monstration de l'extraction de noms de sites
        demo_website_extraction()
        
        # 2. D√©monstration des requ√™tes de base de donn√©es
        demo_database_queries()
        
        # 3. D√©monstration de cr√©ation manuelle
        demo_manual_site_creation()
        
        # 4. Exemples d'utilisation
        demo_usage_examples()
        
        logger.info("\n" + "=" * 60)
        logger.info("‚úÖ D√©monstration termin√©e avec succ√®s")
        logger.info("\nüí° Conseils:")
        logger.info("   - Utilisez reorganize_database.py pour un traitement complet")
        logger.info("   - Utilisez verify_website_relations.py pour v√©rifier l'√©tat")
        logger.info("   - Les relations sont automatiquement g√©r√©es selon les chemins")
        
    except Exception as e:
        logger.error(f"Erreur durant la d√©monstration: {e}")

if __name__ == '__main__':
    main()